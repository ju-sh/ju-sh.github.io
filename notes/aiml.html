<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>AI and ML</title>
  <link rel="stylesheet" type="text/css" href="https://ju-sh.github.io/static/css/main.css" />
</head>
<body>


<nav id="navbar">
  <a href="https://ju-sh.github.io">Home</a>
   | 
  <a href="https://ju-sh.github.io/blog/index.html">Blog</a>
   | 
  <a href="https://ju-sh.github.io/wiki/index.html">Wiki</a>
   | 
  <a href="https://ju-sh.github.io/about.html">About</a>
</nav>

<header id="title-block-header">
      <h1 class="title">AI and ML</h1>
    </header>

<ul>
    </ul>




<hr/>

<main id="content-container">
<ul>
<li><a href="https://en.wikipedia.org/wiki/Transfer_learning">Transfer learning</a>: 'storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks'</li>
<li><a href="https://en.wikipedia.org/wiki/Reinforcement_learning">Reinforcement learning</a>:
<ul>
<li>'focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).'</li>
<li>No need of labelled data or explicit correction. Sort of learns by itself based on what it sees.</li>
<li>'concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward'</li>
</ul></li>
<li>ReLu: Rectified linear unit
<ul>
<li>A popular activation function in ANNs</li>
<li><code>f(x) = max(0, x)</code></li>
</ul></li>
<li><a href="https://en.wikipedia.org/wiki/Meta-learning_(computer_science)">Meta-learning</a>: 'Learning to learn'
<ul>
<li><a href="https://lilianweng.github.io/posts/2018-11-30-meta-learning/">https://lilianweng.github.io/posts/2018-11-30-meta-learning/</a></li>
</ul></li>
<li>Support vector machine (SVM)
<ul>
<li>For (linear) classification problem</li>
<li>Supervised training</li>
</ul></li>
<li>Perceptron (McCulloch-Pitts)</li>
<li>Linear classification
<ul>
<li>Points of different classes drawn on a graph can be demarcated by straight lines</li>
</ul></li>
<li>Support vector machines (SVM): Can do linear classification</li>
</ul>
<ul>
<li>Forecasting algorithms
<ul>
<li>ARIMA (Auto-regressive integrated moving average)</li>
<li>SARIMA (Seasonal auto-regressive integrated moving average)</li>
</ul></li>
<li>Autoregression</li>
<li>Moving average</li>
</ul>
<ul>
<li>Ablation study
<ul>
<li>Ablation =&gt; removing a component of model to see how it performance varies</li>
<li>Useful to gauge the necessity/contribution of a component/architecture/parameter.</li>
<li>Ablation study could be done to show that a newly inserted aspect does indeed make the model better.
<ul>
<li>The model with and without this new aspect can be made, to compare and show that the performance is better with the new aspect.</li>
</ul></li>
<li>Eg: Changing activation function</li>
</ul></li>
<li>Continuous learning
<ul>
<li>Train a model, but the training never stops.</li>
<li>Allow model to learn new things by constantly retraining for it to be able to deal with new kinds of data</li>
<li>Without losing the knowledge gained from previous trainings</li>
<li>Allowing the model to adapt to changing need, without being retrained from scratch.</li>
</ul></li>
<li>Hyperparameter
<ul>
<li>Usually set explicity by the designer. Not 'learned' during training.</li>
<li>These are set <em>before</em> training</li>
<li>Eg: Batch size in training dataset, learning rate</li>
<li>Difference from 'parameter': Parameters are learnt during training process
<ul>
<li>The term parameter refers to <em>model parameters</em>.</li>
<li>Eg: Weights in a neural network, k-value in K-nearest-neighbour</li>
<li><a href="https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/">https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/</a></li>
</ul></li>
</ul></li>
<li>Choosing value of hyperparameters
<ul>
<li>Evaluating AI models</li>
<li>Grid search: Try all possible configurations =&gt; often impractical</li>
<li>Random search: Select random combinations as configurations
<ul>
<li>Results shown to be close enough to grid search</li>
</ul></li>
<li><a href="https://www.kaggle.com/code/willkoehrsen/intro-to-model-tuning-grid-and-random-search">https://www.kaggle.com/code/willkoehrsen/intro-to-model-tuning-grid-and-random-search</a></li>
</ul></li>
</ul>
<ul>
<li>Sobel operator: Used for edge detection in images
<ul>
<li>aka Sobel filter</li>
</ul></li>
<li>Transformers
<ul>
<li>Dethroned CNNs' place as the choice for computer vision</li>
<li>Can handle both text and images</li>
</ul></li>
<li>GPT: Generative Pre-trained Transformers</li>
<li>Diffusion models</li>
<li>GANs: Generative Adversarial Neural-networks
<ul>
<li>Made popular by deepfakes</li>
<li>Made less relevant by diffusion models ??</li>
</ul></li>
<li>RNNs: Recurrent Neural Networks
<ul>
<li>LSTM: Long Short-Term Memory
<ul>
<li>No vanishing gradient problem</li>
</ul></li>
<li>GRU: Gated Recurrent Unit
<ul>
<li>A simplified form of LSTMs</li>
</ul></li>
</ul></li>
</ul>
<h2 id="reinforcement-learning">Reinforcement learning</h2>
<ul>
<li><p>Value iteration</p></li>
<li><p>Q-Learning</p></li>
<li><p>Policy (π)</p>
<ul>
<li>Are probabilities of 'transitions'</li>
<li>P(s'|s, a): probability of going to s' from s by taking action a</li>
<li>Expected utility of a π</li>
<li>Probabilistic =&gt; need not take the same path every time for the same π</li>
<li>π<sup>*</sup>: optimal policy
<ul>
<li>Policy with maximum expected utility</li>
</ul></li>
</ul></li>
<li><p>Discounted rewards</p>
<ul>
<li>Discount factor = γ</li>
</ul></li>
<li><p>R(s): reward associated with state s</p></li>
<li><p>Markov process</p>
<ul>
<li>Next state is independent of history</li>
</ul></li>
<li><p>MDP: Markov decision process</p></li>
</ul>
<p>—</p>
<p>Bellmann equation for utility</p>
<pre><code>U(s) = R(s) + γ max [P(s&#39;|s, a) * U(s&#39;)]
                a∈A
</code></pre>
<p>This essentially says this:</p>
<pre><code>Utility of a state = Reward of that state + Utility of next state
</code></pre>
<h2 id="sketching">Sketching</h2>
<p>From <a href="https://www.sketchingbigdata.org/fall20/lec/notes.pdf">here</a>:</p>
<blockquote>
<p>A sketch C(X) of some data set X with respect to some function f is a compression of X that allows us to compute, or approximately compute, f (X) given access only to C(X).</p>
</blockquote>
<ul>
<li>'compress data in a way that lets you answer queries' <a href="https://people.eecs.berkeley.edu/~minilek/tum2016/notes3.pdf">¹¹</a></li>
<li>Helps save bandwidth when streaming data over a network.</li>
</ul>
<h2 id="fun-facts">Fun facts</h2>
<ul>
<li>Fun fact (2025): PyTorch is the most popular framework used in deep learning research</li>
<li>Hugging Face also provide libraries. Like trainers.
<ul>
<li><a href="https://huggingface.co/docs/transformers/en/main_classes/trainer">https://huggingface.co/docs/transformers/en/main_classes/trainer</a></li>
</ul></li>
</ul>
<h2 id="libraries-and-frameworks">Libraries and frameworks</h2>
<ul>
<li>PyTorch</li>
<li>Tensorflow (dead??)</li>
<li>Theano</li>
<li>Caffe</li>
<li>Keras</li>
</ul>
<h2 id="acks">Acks</h2>
<p>Much of the info here is result of online searches instigated by conversions with the following people: Vishnu, Likith, Eva</p>
</main>
</body>
</html>
